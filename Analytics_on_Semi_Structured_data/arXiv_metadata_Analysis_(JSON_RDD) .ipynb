{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nrTNalW81Uo"
      },
      "source": [
        "# **Arxiv metadata Analytics with PySpark RDD: JSON case study**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ghTJybh281Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2ab932-2006-4c5e-ef51-26e180b8064c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=feb7045da699a06536d4139da829acce9b50f16b2eed258c2c03de2e1ceb81f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "########## ONLY in Colab ##########\n",
        "!pip3 install pyspark\n",
        "########## ONLY in Colab ##########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lv29DcwT81Ut"
      },
      "outputs": [],
      "source": [
        "########## ONLY in Ubuntu Machine ##########\n",
        "# Load Spark engine\n",
        "!pip3 install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "########## ONLY in Ubuntu Machine ##########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "06d5GLeN81Ut"
      },
      "outputs": [],
      "source": [
        "# Initializing Spark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "conf = SparkConf().setAppName(\"Arxiv\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf = conf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YI0-oMwZ6-Y",
        "outputId": "f9c5d3d5-7527-44fd-d428-a15d66bbe9b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UGorHKN581Uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5328c66-2c88-4f50-a0dc-76ff40507125"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[4] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Read and Load Data to Spark\n",
        "# Data source: https://www.kaggle.com/Cornell-University/arxiv/version/62\n",
        "\n",
        "import json\n",
        "\n",
        "# making 100 partitions of the data\n",
        "\n",
        "data = sc.textFile(\"/content/drive/MyDrive/arxiv-metadata-oai-snapshot.json\", 100)\n",
        "rdd = data.map(lambda x: json.loads(x))\n",
        "\n",
        "rdd.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6O_dV30S81Uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b4ec86-cffc-4fd0-bf1e-9b840c3e209c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "# Check the number of parallelism and partitions:\n",
        "print(sc.defaultParallelism)\n",
        "print(rdd.getNumPartitions())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBgW8XMl81Uv"
      },
      "source": [
        "## Question 1: Count elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NzJeaegJ81Uw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7abae5b-36ed-4c24-eb74-6c07c6841f92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2011231"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "rdd.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl7nmy6S81Uw"
      },
      "source": [
        "## Question 2: Get the first two records\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HG1ypizS81Ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fe2852-9c26-4476-9beb-2d5fc1c1b98d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '0704.0001',\n",
              "  'submitter': 'Pavel Nadolsky',\n",
              "  'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
              "  'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
              "  'comments': '37 pages, 15 figures; published version',\n",
              "  'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
              "  'doi': '10.1103/PhysRevD.76.013009',\n",
              "  'report-no': 'ANL-HEP-PR-07-12',\n",
              "  'categories': 'hep-ph',\n",
              "  'license': None,\n",
              "  'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
              "  'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'},\n",
              "   {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}],\n",
              "  'update_date': '2008-11-26',\n",
              "  'authors_parsed': [['Balázs', 'C.', ''],\n",
              "   ['Berger', 'E. L.', ''],\n",
              "   ['Nadolsky', 'P. M.', ''],\n",
              "   ['Yuan', 'C. -P.', '']]},\n",
              " {'id': '0704.0002',\n",
              "  'submitter': 'Louis Theran',\n",
              "  'authors': 'Ileana Streinu and Louis Theran',\n",
              "  'title': 'Sparsity-certifying Graph Decompositions',\n",
              "  'comments': 'To appear in Graphs and Combinatorics',\n",
              "  'journal-ref': None,\n",
              "  'doi': None,\n",
              "  'report-no': None,\n",
              "  'categories': 'math.CO cs.CG',\n",
              "  'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/',\n",
              "  'abstract': '  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n',\n",
              "  'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 02:26:18 GMT'},\n",
              "   {'version': 'v2', 'created': 'Sat, 13 Dec 2008 17:26:00 GMT'}],\n",
              "  'update_date': '2008-12-13',\n",
              "  'authors_parsed': [['Streinu', 'Ileana', ''], ['Theran', 'Louis', '']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "rdd.take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgSYUgiQ81Ux"
      },
      "source": [
        "## Question 3: Get all attributes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4_hnOy9V81Uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dacc1e8-702c-42bf-c3b9-1f02a4d582bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['authors',\n",
              " 'comments',\n",
              " 'title',\n",
              " 'id',\n",
              " 'journal-ref',\n",
              " 'versions',\n",
              " 'submitter',\n",
              " 'categories',\n",
              " 'update_date',\n",
              " 'authors_parsed',\n",
              " 'report-no',\n",
              " 'license',\n",
              " 'abstract',\n",
              " 'doi']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "rdd.flatMap(lambda x: x.keys()).distinct().collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGaQWri681Uy"
      },
      "source": [
        "## Question 4: Get the name of the licenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JjUWgHMs81Uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664aeabb-a1bd-4350-ff36-506f806759d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " 'http://creativecommons.org/licenses/publicdomain/',\n",
              " 'http://creativecommons.org/licenses/by-nc-nd/4.0/',\n",
              " 'http://creativecommons.org/licenses/by-nc-sa/4.0/',\n",
              " 'http://creativecommons.org/licenses/by-nc-sa/3.0/',\n",
              " 'http://creativecommons.org/licenses/by/3.0/',\n",
              " 'http://creativecommons.org/licenses/by/4.0/',\n",
              " 'http://creativecommons.org/publicdomain/zero/1.0/',\n",
              " 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/',\n",
              " 'http://creativecommons.org/licenses/by-sa/4.0/']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "rdd.map(lambda x: x['license']).distinct().collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_giGZDm981Uz"
      },
      "source": [
        "## Question 5: Get the shortest and the longest titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0ujiDBLl81Uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36bc31fe-768f-4676-8d28-6479bd6d3701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!-Graphs with Trivial Overlap are Context-Free\n",
            "Weyl formula for the negative dissipative eigenvalues of Maxwell's\n",
            "  equations\n"
          ]
        }
      ],
      "source": [
        "short_title = rdd.map(lambda x: x['title']).min()\n",
        "long_title = rdd.map(lambda x: x['title']).max()\n",
        "\n",
        "print(short_title)\n",
        "print(long_title)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "short_title = rdd.map(lambda x: x['title']).reduce(lambda x,y: x if x < y else y)\n",
        "long_title = rdd.map(lambda x: x['title']).reduce(lambda x,y: x if x > y else y)\n",
        "\n",
        "print(short_title)\n",
        "print(long_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbrsAKccgJCN",
        "outputId": "e381422a-f5e7-4a02-fd65-cb0c2a8536cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!-Graphs with Trivial Overlap are Context-Free\n",
            "Weyl formula for the negative dissipative eigenvalues of Maxwell's\n",
            "  equations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9iSZAe281Uz"
      },
      "source": [
        "## Question 6: Find abbreviations with 5 or more letters in the abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_abbrivations(line):\n",
        "  result = re.search(r\"\\(([A-Za-z][^_/\\\\<>]{5,})\\)\", line)\n",
        "  if result:\n",
        "    return result.group(1)"
      ],
      "metadata": {
        "id": "Gs2mIZTFj7JV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z1Weltn281U0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b2ca42-d495-4441-9a38-477c404f65ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "702869"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "rdd.filter(lambda x:get_abbrivations(x['abstract'])).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnPa1NYL81U0"
      },
      "source": [
        "## Question 7: Get the number of archive records per month ('update_date' attribute)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0Wsgod6K81U1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a7f5ad-dbf5-49ca-d39d-9441561e391c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "def extract_month(datein):\n",
        "  d = datetime.datetime.strptime(datein, '%Y-%m-%d')\n",
        "  return d.month\n",
        "\n",
        "extract_month('2024-10-17')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.map(lambda x: (extract_month(x['update_date']),1)).reduceByKey(lambda x,y: x+y).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uigm5_37nNed",
        "outputId": "e5ee3559-ad23-4874-dbc8-01b139977d9a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 134247),\n",
              " (2, 116948),\n",
              " (3, 126458),\n",
              " (4, 117126),\n",
              " (5, 296587),\n",
              " (6, 191746),\n",
              " (7, 122649),\n",
              " (8, 138469),\n",
              " (9, 138978),\n",
              " (10, 197755),\n",
              " (11, 297963),\n",
              " (12, 132305)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQu2A93481U1"
      },
      "source": [
        "## Question 8: Get the average number of pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Wa1y3OKW81U1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03b1603-f547-4283-b7e3-a702a38dcca5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "def get_pages(line):\n",
        "  search = re.findall(r\"\\d+ pages\", line)\n",
        "  if search:\n",
        "    return int(search[0].split(\" \")[0])\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "get_pages('there are 100 pages')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_average = rdd.map(lambda x: get_pages(x['comments'] if x['comments'] != None else \"None\"))\n",
        "rdd_average = rdd_average.filter(lambda x: x != 0)\n",
        "\n",
        "average_counter = rdd_average.count()\n",
        "average_summation = rdd_average.reduce(lambda x,y: x+y)\n",
        "print(average_counter)\n",
        "print(average_summation)\n",
        "print(\"Average of pages\", (average_summation/average_counter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCfn0b_VpIeX",
        "outputId": "23766d00-6f05-4c25-fe87-0025a8e5d4a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1184075\n",
            "21139516\n",
            "Average of pages 17.85319004286046\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}